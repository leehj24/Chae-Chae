# app.py (ì„±ëŠ¥ ë° ë©”ëª¨ë¦¬ ìµœì í™” ìµœì¢…ë³¸)

import json, time, traceback, re, os, threading, math, uuid
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Tuple, Optional

import numpy as np
import pandas as pd
import unicodedata as ud
import requests
from werkzeug.utils import secure_filename
from flask import (Flask, Response, redirect, render_template, request, session, url_for, abort, send_from_directory)
from flask_session import Session

from recommend.config import (PATH_TMF, KAKAO_API_KEY, PATH_KAKAO_IMAGE_CACHE, KAKAO_JS_KEY)
import recommend.run_walk as run_walk_module
import recommend.run_transit as run_transit_module

# --- Flask ì•± ì„¤ì • ---
BASE_DIR = Path(__file__).resolve().parent
app = Flask(__name__, template_folder=str(BASE_DIR / "templates"), static_folder=str(BASE_DIR / "static"))
app.secret_key = os.environ.get("FLASK_SECRET_KEY", "dev-secret-key-for-testing")
UPLOAD_FOLDER = str(BASE_DIR / "uploads")
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'webp'}
Path(UPLOAD_FOLDER).mkdir(exist_ok=True)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 8 * 1024 * 1024
app.config.update(
    SESSION_TYPE="filesystem",
    SESSION_FILE_DIR=str((BASE_DIR / "_fs_sessions").resolve()),
    SESSION_PERMANENT=False,
    SESSION_USE_SIGNER=True,
    SESSION_COOKIE_NAME="srv_session",
)
Path(app.config["SESSION_FILE_DIR"]).mkdir(parents=True, exist_ok=True)
Session(app)

# --- ìƒìˆ˜ ë° ì´ˆê¸° ì„¤ì • ---
BOT_PROMPTS = {
    "ì§€ì—­": "ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š<br /><b>ì–´ë–¤ ì§€ì—­</b>ìœ¼ë¡œ ì—¬í–‰ ê°€ì‹¤ ê±´ê°€ìš”?",
    "ì ìˆ˜": "ì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ ì¶”ì²œí• ê¹Œìš”? <b>ê´€ê´‘ì§€ìˆ˜ vs ì¸ê¸°ë„ì§€ìˆ˜</b><br />í•˜ë‚˜ë§Œ ì„ íƒí•´ ì£¼ì„¸ìš”.",
    "í…Œë§ˆ": "ì¢‹ì•„ìš”! ì´ì œ <b>ì›í•˜ëŠ” í…Œë§ˆë¥¼ ìµœëŒ€ 3ê°œ</b>ê¹Œì§€ ê³¨ë¼ì£¼ì„¸ìš”.",
    "ê¸°ê°„": "<b>ì—¬í–‰ ê¸°ê°„</b>ì„ ì„ íƒí•´ ì£¼ì„¸ìš”. ì‹œì‘~ì¢…ë£Œ ë‚ ì§œë¥¼ ê³ ë¥´ë©´ <em>ì´ ì¼ìˆ˜</em>ê°€ ìë™ ê³„ì‚°ë¼ìš”.",
    "ì´ë™ìˆ˜ë‹¨": "ë§ˆì§€ë§‰ìœ¼ë¡œ, <b>ì–´ë–¤ ì´ë™ìˆ˜ë‹¨</b>ìœ¼ë¡œ ë§ì¶œê¹Œìš”?",
    "ì‹¤í–‰ì¤‘": "<div class='spinner'></div>ëª¨ë“  ì •ë³´ë¥¼ í™•ì¸í–ˆì–´ìš”.<br>ì´ì œ ìµœì ì˜ ì—¬í–‰ ê²½ë¡œë¥¼ ë§Œë“¤ê³  ìˆì–´ìš”. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”!",
}
sido_map = {
    'ì„œìš¸': 'ì„œìš¸íŠ¹ë³„ì‹œ', 'ì„œìš¸íŠ¹ë³„ì‹œ': 'ì„œìš¸íŠ¹ë³„ì‹œ', 'ì„œìš¸ì‹œ': 'ì„œìš¸íŠ¹ë³„ì‹œ', 'ë¶€ì‚°': 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ë¶€ì‚°ê´‘ì—­ì‹œ': 'ë¶€ì‚°ê´‘ì—­ì‹œ',
    'ëŒ€êµ¬': 'ëŒ€êµ¬ê´‘ì—­ì‹œ', 'ëŒ€êµ¬ê´‘ì—­ì‹œ': 'ëŒ€êµ¬ê´‘ì—­ì‹œ', 'ì¸ì²œ': 'ì¸ì²œê´‘ì—­ì‹œ', 'ì¸ì²œê´‘ì—­ì‹œ': 'ì¸ì²œê´‘ì—­ì‹œ',
    'ê´‘ì£¼': 'ê´‘ì£¼ê´‘ì—­ì‹œ', 'ê´‘ì£¼ê´‘ì—­ì‹œ': 'ê´‘ì£¼ê´‘ì—­ì‹œ', 'ëŒ€ì „': 'ëŒ€ì „ê´‘ì—­ì‹œ', 'ëŒ€ì „ê´‘ì—­ì‹œ': 'ëŒ€ì „ê´‘ì—­ì‹œ',
    'ìš¸ì‚°': 'ìš¸ì‚°ê´‘ì—­ì‹œ', 'ìš¸ì‚°ê´‘ì—­ì‹œ': 'ìš¸ì‚°ê´‘ì—­ì‹œ', 'ìš¸ì‚°ì‹œ': 'ìš¸ì‚°ê´‘ì—­ì‹œ', 'ì„¸ì¢…': 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ', 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ': 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ',
    'ê²½ê¸°': 'ê²½ê¸°ë„', 'ê²½ê¸°ë„': 'ê²½ê¸°ë„', 'ê°•ì›': 'ê°•ì›', 'ê°•ì›ë„': 'ê°•ì›', 'ê°•ì›íŠ¹ë³„ìì¹˜ë„': 'ê°•ì›',
    'ì¶©ë‚¨': 'ì¶©ì²­ë‚¨ë„', 'ì¶©ì²­ë‚¨ë„': 'ì¶©ì²­ë‚¨ë„', 'ì¶©ë¶': 'ì¶©ì²­ë¶ë„', 'ì¶©ì²­ë¶ë„': 'ì¶©ì²­ë¶ë„',
    'ì „ë‚¨': 'ì „ë¼ë‚¨ë„', 'ì „ë¼ë‚¨ë„': 'ì „ë¼ë‚¨ë„', 'ì „ë¶': 'ì „ë¼ë¶ë„', 'ì „ë¼ë¶ë„': 'ì „ë¼ë¶ë„', 'ì „ë¶íŠ¹ë³„ìì¹˜ë„': 'ì „ë¼ë¶ë„',
    'ê²½ë‚¨': 'ê²½ìƒë‚¨ë„', 'ê²½ìƒë‚¨ë„': 'ê²½ìƒë‚¨ë„', 'ê²½ë¶': 'ê²½ìƒë¶ë„', 'ê²½ìƒë¶ë„': 'ê²½ìƒë¶ë„',
    'ì œì£¼': 'ì œì£¼', 'ì œì£¼ë„': 'ì œì£¼', 'ì œì£¼íŠ¹ë³„ìì¹˜ë„': 'ì œì£¼',
}
MAX_MSGS = 30
PATH_USER_REVIEWS = str(BASE_DIR / "_user_reviews.json")
_USER_REVIEWS_CACHE = {"data": None, "mtime": None}
_USER_REVIEWS_LOCK = threading.Lock()
PATH_USER_UPLOADS = str(BASE_DIR / "_user_uploads.json")
_USER_UPLOADS_CACHE = {"data": None, "mtime": None}
_USER_UPLOADS_LOCK = threading.Lock()
_IMAGE_CACHE: dict[str, dict] | None = None
_SESSION: requests.Session | None = None
DEFAULT_UA = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"

PLACES_DF = None
FILTER_OPTIONS = None

# --- ë°ì´í„° ë¡œë”© ë° ìµœì í™” ---

def _read_csv_robust(path: str, usecols: Optional[List[str]] = None) -> pd.DataFrame:
    for enc in ("utf-8", "utf-8-sig", "cp949"):
        try:
            return pd.read_csv(path, encoding=enc, usecols=usecols)
        except Exception:
            pass
    raise IOError(f"Failed to read CSV file with common encodings: {path}")

def _pick_column(df_cols: List[str], *names: str) -> str | None:
    low_cols = {c.lower().strip(): c for c in df_cols}
    for n in names:
        if n.lower() in low_cols:
            return low_cols[n.lower()]
    # Fallback for partial matches
    for c in df_cols:
        cl = c.lower().strip()
        for n in names:
            if n.lower() in cl:
                return c
    return None

def load_places_data() -> Tuple[pd.DataFrame, Dict[str, List[str]]]:
    """
    [ìˆ˜ì •] ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•œ ë°ì´í„° ë¡œë”© í•¨ìˆ˜.
    1. í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì •í™•íˆ ì§€ì •í•˜ì—¬ ë¡œë“œ.
    2. ë¬¸ìì—´ ì»¬ëŸ¼ì€ 'category' íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë©”ëª¨ë¦¬ ì ˆì•½.
    3. ìˆ«ìí˜• ì»¬ëŸ¼ì€ 'float32'ë¡œ ë³€í™˜.
    """
    print("ğŸš€ ì•± ì‹œì‘! ê´€ê´‘ì§€ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ê³  ìµœì í™”í•©ë‹ˆë‹¤...")

    required_cols_map = {
        "title": ["title", "ëª…ì¹­", "ì¥ì†Œëª…"],
        "addr1": ["addr1", "ì£¼ì†Œ", "ì†Œì¬ì§€"],
        "cat1": ["cat1", "ëŒ€ë¶„ë¥˜"],
        "cat3": ["cat3", "ì†Œë¶„ë¥˜"],
        "tour_score": ["tour_score", "ê´€ê´‘ì§€ìˆ˜"],
        "review_score": ["review_score", "ì¸ê¸°ë„ì§€ìˆ˜"],
        "mapx": ["mapx", "x", "lon", "ê²½ë„"],
        "mapy": ["mapy", "y", "lat", "ìœ„ë„"],
        "firstimage": ["firstimage", "ëŒ€í‘œì´ë¯¸ì§€", "ì´ë¯¸ì§€"],
    }
    
    try:
        temp_df_cols = pd.read_csv(PATH_TMF, encoding='utf-8', nrows=0).columns.tolist()
    except Exception:
        temp_df_cols = pd.read_csv(PATH_TMF, encoding='cp949', nrows=0).columns.tolist()

    cols_to_load = {}
    final_col_names = []
    for key, candidates in required_cols_map.items():
        found_col = _pick_column(temp_df_cols, *candidates)
        if found_col:
            cols_to_load[key] = found_col
            final_col_names.append(found_col)
        elif key not in ["cat3", "firstimage"]:
             raise KeyError(f"í•„ìˆ˜ ì»¬ëŸ¼ '{key}'ì— í•´ë‹¹í•˜ëŠ” ì»¬ëŸ¼ì„ CSVì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {candidates}")

    df = _read_csv_robust(PATH_TMF, usecols=list(set(final_col_names)))
    
    rename_map = {v: k for k, v in cols_to_load.items()}
    df = df.rename(columns=rename_map)

    for c in ("cat3", "firstimage"):
        if c not in df.columns: df[c] = ""

    df['title'] = df['title'].astype(str).str.strip()
    df['addr1'] = df['addr1'].astype(str).str.strip()
    df = df.dropna(subset=['title', 'addr1'])
    df = df[df['title'] != '']
    df = df.drop_duplicates(subset=["title", "addr1"], keep="first").reset_index(drop=True)

    print("âœ… CSV ë¡œë“œ ì™„ë£Œ. ì´ì œ ë°ì´í„° íƒ€ì…ì„ ìµœì í™”í•©ë‹ˆë‹¤...")
    
    # ì£¼ì†Œì—ì„œ ì‹œë„(sido) ì •ë³´ ì¶”ì¶œ í›„ category íƒ€ì…ìœ¼ë¡œ ë³€í™˜
    df['sido'] = df['addr1'].astype(str).str.split().str[0].astype('category')
    
    for col in df.columns:
        if 'score' in col or col in ['mapx', 'mapy']:
            df[col] = pd.to_numeric(df[col], errors='coerce').astype('float32')
        elif df[col].dtype == 'object':
            df[col] = df[col].fillna("").astype(str)
            # ìœ ë‹ˆí¬í•œ ê°’ì´ ì ì€ ì»¬ëŸ¼ì„ 'category'ë¡œ ë³€í™˜
            if col in ['cat1']:
                num_unique_values = df[col].nunique()
                if num_unique_values / len(df) < 0.5:
                    df[col] = df[col].astype('category')

    print("âœ… ë°ì´í„° íƒ€ì… ìµœì í™” ì™„ë£Œ!")
    df.info(memory_usage='deep')
    
    sidos = sorted([s for s in df['sido'].cat.categories if s])
    cat1s = sorted([c for c in df['cat1'].cat.categories if c])
    
    all_cat3s = set()
    df['cat3'].astype(str).str.split(r'[,/|]').dropna().apply(
        lambda tags: all_cat3s.update(t.strip() for t in tags if t.strip())
    )
    cat3s = sorted(list(all_cat3s))
    
    filter_opts = {"sidos": sidos, "cat1s": cat1s, "cat3s": cat3s}
    
    print(f"âœ… ë°ì´í„° ë¡œë“œ ë° ìµœì í™” ìµœì¢… ì™„ë£Œ! ì´ {len(df):,}ê°œì˜ ì¥ì†Œ.")
    return df, filter_opts


PLACES_DF, FILTER_OPTIONS = load_places_data()


# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ---

def _sort_key_from_param(s: str) -> tuple[str, str]:
    s = (s or "").strip().lower()
    return ("review_score", "ì¸ê¸°ë„ ì§€ìˆ˜") if s in {"popular", "review", "review_score", "ì¸ê¸°ë„"} else ("tour_score", "ê´€ê´‘ ì§€ìˆ˜")

def _trim_msgs():
    session["messages"] = session.get("messages", [])[-MAX_MSGS:]

def _json(payload: Dict[str, Any], status: int = 200) -> Response:
    return app.response_class(response=json.dumps(payload, ensure_ascii=False, allow_nan=False), status=status, mimetype="application/json")

def _df_to_records(df: pd.DataFrame) -> List[Dict[str, Any]]:
    clean = df.replace({np.nan: None})
    recs = clean.to_dict(orient="records")
    for r in recs:
        for k, v in list(r.items()):
            if isinstance(v, np.generic): r[k] = v.item()
    return recs

def _nfc(s: str) -> str:
    return ud.normalize("NFC", str(s or "")).strip()

def _init_session_if_needed():
    if "state" not in session: session["state"] = "ì§€ì—­"
    if "messages" not in session or not session["messages"]: session["messages"] = [{"sender": "bot", "html": BOT_PROMPTS["ì§€ì—­"]}]
    if 'user_id' not in session:
        session['user_id'] = str(uuid.uuid4())

def _allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def _load_user_reviews():
    with _USER_REVIEWS_LOCK:
        p = Path(PATH_USER_REVIEWS)
        if not p.exists(): return {}
        try:
            mtime = p.stat().st_mtime
            if _USER_REVIEWS_CACHE["data"] is not None and _USER_REVIEWS_CACHE["mtime"] == mtime:
                return _USER_REVIEWS_CACHE["data"]
            data = json.loads(p.read_text(encoding="utf-8"))
            _USER_REVIEWS_CACHE["data"] = data
            _USER_REVIEWS_CACHE["mtime"] = mtime
            return data
        except (json.JSONDecodeError, IOError):
            return {}

def _save_user_reviews(data):
    with _USER_REVIEWS_LOCK:
        try:
            p = Path(PATH_USER_REVIEWS)
            p.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
            _USER_REVIEWS_CACHE["data"] = None
            _USER_REVIEWS_CACHE["mtime"] = None
        except Exception as e:
            print(f"âŒ ì—ëŸ¬: ì‚¬ìš©ì í›„ê¸° íŒŒì¼ ì €ì¥ ì‹¤íŒ¨ - {e}")

def _load_user_uploads():
    with _USER_UPLOADS_LOCK:
        p = Path(PATH_USER_UPLOADS)
        if not p.exists(): return {}
        try:
            mtime = p.stat().st_mtime
            if _USER_UPLOADS_CACHE["data"] is not None and _USER_UPLOADS_CACHE["mtime"] == mtime: return _USER_UPLOADS_CACHE["data"]
            data = json.loads(p.read_text(encoding="utf-8"))
            _USER_UPLOADS_CACHE["data"] = data
            _USER_UPLOADS_CACHE["mtime"] = mtime
            return data
        except (json.JSONDecodeError, IOError): return {}

def _save_user_uploads(data):
    with _USER_UPLOADS_LOCK:
        try:
            p = Path(PATH_USER_UPLOADS)
            p.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
            _USER_UPLOADS_CACHE["data"] = None
            _USER_UPLOADS_CACHE["mtime"] = None
        except Exception as e:
            print(f"âŒ ì—ëŸ¬: ì‚¬ìš©ì ì—…ë¡œë“œ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨ - {e}")

def _load_image_cache() -> dict:
    global _IMAGE_CACHE
    if _IMAGE_CACHE is not None: return _IMAGE_CACHE
    p = Path(PATH_KAKAO_IMAGE_CACHE)
    if not p.exists(): _IMAGE_CACHE = {}; return _IMAGE_CACHE
    try: _IMAGE_CACHE = json.loads(p.read_text(encoding="utf-8"))
    except (json.JSONDecodeError, IOError): print(f"âš ï¸ ê²½ê³ : '{PATH_KAKAO_IMAGE_CACHE}' íŒŒì¼ì„ ì½ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¹ˆ ìºì‹œë¡œ ì‹œì‘í•©ë‹ˆë‹¤."); _IMAGE_CACHE = {}
    return _IMAGE_CACHE

def _save_image_cache():
    global _IMAGE_CACHE
    if _IMAGE_CACHE is None: return
    try: p = Path(PATH_KAKAO_IMAGE_CACHE); p.write_text(json.dumps(_IMAGE_CACHE, ensure_ascii=False, indent=2), encoding="utf-8")
    except Exception as e: print(f"âŒ ì—ëŸ¬: ì´ë¯¸ì§€ ìºì‹œ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨ - {e}")

def _ensure_session():
    global _SESSION
    if _SESSION is None: _SESSION = requests.Session(); _SESSION.headers.update({"User-Agent": DEFAULT_UA})
    if KAKAO_API_KEY and "Authorization" not in _SESSION.headers: _SESSION.headers.update({"Authorization": f"KakaoAK {KAKAO_API_KEY}"})

def _addr_region_tokens(addr1: str) -> List[str]:
    cand = re.findall(r"\b[\wê°€-í£]+(?:ì‹œ|êµ°|êµ¬)\b", _nfc(addr1)) or re.split(r"[,\s]+", _nfc(addr1)); return [w for w in cand if w][:3]

def _kakao_image_search(query: str, size: int = 4) -> List[str]:
    if not KAKAO_API_KEY: return []
    _ensure_session()
    try:
        params = {"query": query, "sort": "accuracy", "page": 1, "size": max(1, min(10, int(size)))}; r = _SESSION.get("https://dapi.kakao.com/v2/search/image", params=params, timeout=4)
        if not r.ok: return []
        docs = r.json().get("documents", []) or []; urls = [d.get("image_url") for d in docs if str(d.get("image_url") or "").startswith("http")]
        return [u for u in urls if len(u) < 2000]
    except Exception: return []

def _images_for_place(title: str, addr1: str, max_n: int = 4) -> List[str]:
    cache = _load_image_cache(); key = f"{_nfc(title)}|{_nfc(addr1)}"
    if key in cache: return cache[key].get("urls", [])[:max_n]
    return []

def _fetch_and_cache_images_live(title: str, addr1: str) -> list[str]:
    key = f"{_nfc(title)}|{_nfc(addr1)}"; query = " ".join([title, *_addr_region_tokens(addr1)]); urls = _kakao_image_search(query, size=4); cache = _load_image_cache(); cache[key] = {"q": query, "urls": urls, "ts": int(datetime.now().timestamp())}; _save_image_cache(); return urls

def _get_all_images_for_place(title: str, addr1: str, firstimage_url: str | None, max_n: int = 4, include_user_uploads: bool = False, auto_fetch_if_needed: bool = False) -> List[str]:
    key = f"{_nfc(title)}|{_nfc(addr1)}"
    csv_imgs: list[str] = []
    u = str(firstimage_url or '').strip()
    if u and u.lower().startswith('http'):
        csv_imgs.append(u)
    
    kakao_imgs = _images_for_place(title, addr1, max_n=4)
    if not kakao_imgs and auto_fetch_if_needed:
        kakao_imgs = _fetch_and_cache_images_live(title, addr1)
    
    user_imgs: list[str] = []
    if include_user_uploads:
        uploads_db = _load_user_uploads()
        user_uploads = uploads_db.get(key, [])
        user_imgs = [url_for('uploaded_file', filename=f) for f in user_uploads]

    # ì¤‘ë³µ ì œê±° ë° ìˆœì„œ ë³´ì¥ (CSV ëŒ€í‘œì´ë¯¸ì§€ -> ì¹´ì¹´ì˜¤ ì´ë¯¸ì§€ -> ì‚¬ìš©ì ì—…ë¡œë“œ)
    ordered: list[str] = []
    seen = set()
    for img_list in [csv_imgs, kakao_imgs, user_imgs]:
        for img_url in img_list:
            if img_url and img_url not in seen:
                seen.add(img_url)
                ordered.append(img_url)
    return ordered[:max_n]

def _kakao_geocode_coords(query: str, addr1: str = "") -> Optional[Tuple[float, float]]:
    if not KAKAO_API_KEY: return None
    _ensure_session()
    try:
        # ì£¼ì†Œ ìš°ì„  ê²€ìƒ‰
        if addr1:
            r = _SESSION.get("https://dapi.kakao.com/v2/local/search/address.json", params={"query": addr1}, timeout=4)
            if r.ok and r.json().get("documents"):
                d = r.json()["documents"][0]
                return float(d["y"]), float(d["x"])
        # í‚¤ì›Œë“œ ê²€ìƒ‰
        q_kw = " ".join([_nfc(query), *_addr_region_tokens(addr1)])
        r = _SESSION.get("https://dapi.kakao.com/v2/local/search/keyword.json", params={"query": q_kw, "size": 1}, timeout=4)
        if r.ok and r.json().get("documents"):
            d = r.json()["documents"][0]
            return float(d["y"]), float(d["x"])
    except Exception: pass
    return None

def _get_kakao_place_url(title: str, x: str, y: str) -> Optional[str]:
    if not KAKAO_API_KEY or not x or not y: return None
    _ensure_session()
    params = {"query": title, "x": x, "y": y, "radius": 500, "sort": "accuracy", "size": 5}
    try:
        res = _SESSION.get("https://dapi.kakao.com/v2/local/search/keyword.json", params=params, timeout=3)
        if not res.ok: return None
        docs = res.json().get("documents", [])
        if not docs: return None
        # ì´ë¦„ì´ ê°€ì¥ ìœ ì‚¬í•œ ì¥ì†Œì˜ URL ë°˜í™˜
        clean_title = re.sub(r'[\(\)\[\]\s]', '', title)
        for place in docs:
            place_name = re.sub(r'[\(\)\[\]\s]', '', place.get("place_name", ""))
            if clean_title in place_name or place_name in clean_title:
                return place.get("place_url")
        return docs[0].get("place_url") # ìœ ì‚¬í•œ ì¥ì†Œê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜
    except requests.exceptions.RequestException:
        return None

def start_self_pinging():
    def self_ping_task():
        ping_url = os.environ.get("RENDER_EXTERNAL_URL")
        if not ping_url: print("âš ï¸ self-ping: RENDER_EXTERNAL_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì—†ì–´ ì…€í”„ í•‘ì„ ê±´ë„ˆëœë‹ˆë‹¤."); return
        interval_seconds = 600; print(f"ğŸš€ self-ping: ì…€í”„ í•‘ ìŠ¤ë ˆë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ëŒ€ìƒ: {ping_url}, ì£¼ê¸°: {interval_seconds}ì´ˆ")
        while True:
            try:
                time.sleep(interval_seconds)
                print(f"â° self-ping: ì„œë²„ê°€ ì ë“¤ì§€ ì•Šë„ë¡ ìŠ¤ìŠ¤ë¡œë¥¼ ê¹¨ì›ë‹ˆë‹¤... (-> {ping_url})")
                requests.get(ping_url, timeout=10)
            except requests.exceptions.RequestException as e: print(f"âŒ self-ping: ì…€í”„ í•‘ ì‹¤íŒ¨: {e}")
            except Exception as e: print(f"âŒ self-ping: ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
    ping_thread = threading.Thread(target=self_ping_task, daemon=True); ping_thread.start()


# --- ë¼ìš°íŠ¸(Routes) ---

@app.get("/")
def home():
    return render_template("home.html")

@app.get("/chat")
def index():
    _init_session_if_needed()
    return render_template("index.html", kakao_js_key=KAKAO_JS_KEY)

@app.post("/chat")
def chat():
    _init_session_if_needed(); state = session.get("state"); messages = session.get("messages", [])
    if state == "ì§€ì—­":
        region = request.form.get("region", "").strip()
        if region: session["region"] = region; messages.append({"sender": "user", "text": region}); messages.append({"sender": "bot", "html": BOT_PROMPTS["ì ìˆ˜"]}); session["state"] = "ì ìˆ˜"
    elif state == "ì ìˆ˜":
        score = request.form.get("score", "").strip()
        if score in {"ê´€ê´‘ì§€ìˆ˜", "ì¸ê¸°ë„ì§€ìˆ˜"}: session["score_label"] = score; messages.append({"sender": "user", "text": score}); messages.append({"sender": "bot", "html": BOT_PROMPTS["í…Œë§ˆ"]}); session["state"] = "í…Œë§ˆ"
    elif state == "í…Œë§ˆ":
        themes_str = request.form.get("themes", "").strip()
        if themes_str:
            themes = [t.strip() for t in themes_str.split(",") if t.strip()]; session["cats"] = themes; messages.append({"sender": "user", "text": ", ".join(themes)}); messages.append({"sender": "bot", "html": BOT_PROMPTS["ê¸°ê°„"]}); session["state"] = "ê¸°ê°„"
    elif state == "ê¸°ê°„":
        start_date_str = request.form.get("start_date"); end_date_str = request.form.get("end_date")
        try:
            start = datetime.strptime(start_date_str, "%Y-%m-%d").date(); end = datetime.strptime(end_date_str, "%Y-%m-%d").date(); days = (end - start).days + 1
            if 1 <= days <= 100: session["days"] = days; user_text = f"{start_date_str} ~ {end_date_str} (ì´ {days}ì¼)"; messages.append({"sender": "user", "text": user_text}); messages.append({"sender": "bot", "html": BOT_PROMPTS["ì´ë™ìˆ˜ë‹¨"]}); session["state"] = "ì´ë™ìˆ˜ë‹¨"
        except (ValueError, TypeError): pass
    elif state == "ì´ë™ìˆ˜ë‹¨":
        transport = request.form.get("transport", "").strip()
        if transport in {"walk", "transit"}: session["transport_mode"] = transport; transport_text = "ê±·ê¸°" if transport == "walk" else "ëŒ€ì¤‘êµí†µ"; messages.append({"sender": "user", "text": transport_text}); messages.append({"sender": "bot", "html": BOT_PROMPTS["ì‹¤í–‰ì¤‘"]}); session["state"] = "ì‹¤í–‰ì¤‘"
    session["messages"] = messages; _trim_msgs(); return redirect(url_for("index"))

@app.post("/do_generate")
def do_generate():
    try:
        params = {"region": session.get("region"),"score_label": session.get("score_label"),"cats": session.get("cats"),"days": session.get("days"),"transport_mode": session.get("transport_mode"),}
        if not all(params.values()): raise ValueError("í•„ìˆ˜ ì…ë ¥ê°’ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        engine = run_walk_module if params["transport_mode"] == "walk" else run_transit_module; itinerary_df = engine.run(**params); session["itinerary"] = _df_to_records(itinerary_df); session["state"] = "ì™„ë£Œ"; messages = session.get("messages", [])
        completion_html = "ì™„ë£Œ! ì¶”ì²œ ì¼ì •ì„ ì•„ë˜ì— í‘œì‹œí–ˆì–´ìš”."
        if messages and messages[-1].get("sender") == "bot" and "spinner" in messages[-1].get("html", ""): messages[-1]["html"] = completion_html
        else: messages.append({"sender": "bot", "html": completion_html})
        session["messages"] = messages; return _json({"ok": True})
    except Exception as e:
        trace = traceback.format_exc(limit=4); print(f"Generation Error: {e}\n{trace}"); session["state"] = "ì˜¤ë¥˜"; session["messages"].append({"sender": "bot", "html": f"<strong>ì˜¤ë¥˜ ë°œìƒ:</strong><br><pre>{e}</pre>"}); return _json({"ok": False, "error": str(e)}, 500)

@app.get("/reset_chat")
def reset_chat():
    session.clear(); return redirect(url_for("index"))

@app.get("/go_back")
def go_back():
    _init_session_if_needed(); current_state = session.get("state"); state_flow = {"ì ìˆ˜": "ì§€ì—­", "í…Œë§ˆ": "ì ìˆ˜", "ê¸°ê°„": "í…Œë§ˆ", "ì´ë™ìˆ˜ë‹¨": "ê¸°ê°„", "ì‹¤í–‰ì¤‘": "ì´ë™ìˆ˜ë‹¨", "ì™„ë£Œ": "ì´ë™ìˆ˜ë‹¨", "ì˜¤ë¥˜": "ì´ë™ìˆ˜ë‹¨"}
    prev_state = state_flow.get(current_state)
    if prev_state:
        messages = session.get("messages", [])
        if len(messages) >= 2: session["messages"] = messages[:-2]
        session["state"] = prev_state
    else: session.clear()
    return redirect(url_for("index"))

@app.get("/api/filter-options")
def api_filter_options():
    try:
        return _json({"ok": True, "options": FILTER_OPTIONS})
    except Exception as e:
        traceback.print_exc()
        return _json({"ok": False, "error": str(e)}, 500)

@app.get("/uploads/<path:filename>")
def uploaded_file(filename):
    return send_from_directory(app.config["UPLOAD_FOLDER"], filename)

@app.post("/api/upload-image")
def upload_image():
    title = request.form.get('title'); addr1 = request.form.get('addr1')
    if 'file' not in request.files or not title or not addr1: return _json({"ok": False, "error": "í•„ìˆ˜ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."}, 400)
    file = request.files['file']
    if file.filename == '' or not _allowed_file(file.filename): return _json({"ok": False, "error": "í—ˆìš©ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤."}, 400)
    
    key = f"{_nfc(title)}|{_nfc(addr1)}"
    
    place_rows = PLACES_DF[(PLACES_DF['title'] == title) & (PLACES_DF['addr1'] == addr1)]
    firstimage_url = place_rows.iloc[0]['firstimage'] if not place_rows.empty else None
    
    all_images_before_upload = _get_all_images_for_place(title, addr1, firstimage_url, include_user_uploads=True)
    if len(all_images_before_upload) >= 4: return _json({"ok": False, "error": "ì´ë¯¸ì§€ë¥¼ ìµœëŒ€ 4ê°œê¹Œì§€ ë“±ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."}, 400)
    
    ext = file.filename.rsplit('.', 1)[1].lower()
    filename = secure_filename(f"{uuid.uuid4()}.{ext}")
    file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))
    
    uploads = _load_user_uploads()
    uploads.setdefault(key, []).append(filename)
    _save_user_uploads(uploads)
    
    all_images_after_upload = _get_all_images_for_place(title, addr1, firstimage_url, include_user_uploads=True)
    return _json({"ok": True, "images": all_images_after_upload})

@app.get("/api/places")
def api_places():
    """
    [ìˆ˜ì •] ë©”ì¸ ê·¸ë¦¬ë“œ ë°ì´í„° API. ì´ë¯¸ì§€ ë¡œë”© ë¡œì§ì„ ì œê±°í•˜ì—¬ ì‘ë‹µ ì†ë„ë¥¼ ëŒ€í­ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
    - ë™ê¸°ì ì¸ ì´ë¯¸ì§€ ê²€ìƒ‰(_get_all_images_for_place)ì„ í˜¸ì¶œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    - CSVì— ìˆëŠ” ëŒ€í‘œì´ë¯¸ì§€(firstimage) URL í•˜ë‚˜ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        sido = request.args.get("sido"); cat1 = request.args.get("cat1"); cat3 = request.args.get("cat3"); query = request.args.get("q")
        
        # [ìˆ˜ì •] .copy()ë¥¼ ì œê±°í•˜ì—¬ ë¶ˆí•„ìš”í•œ ë©”ëª¨ë¦¬ ë³µì‚¬ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
        filtered_df = PLACES_DF
        
        if sido and sido != 'all':
            filtered_df = filtered_df[filtered_df['sido'] == sido]
        if cat1 and cat1 != 'all': filtered_df = filtered_df[filtered_df['cat1'] == cat1]
        if cat3 and cat3 != 'all': filtered_df = filtered_df[filtered_df['cat3'].astype(str).str.contains(cat3, na=False)]
        if query: 
            query_nfc = _nfc(query).lower()
            filtered_df = filtered_df[filtered_df['title'].astype(str).str.lower().str.contains(query_nfc, na=False)]

        sort = request.args.get("sort", "review"); order = request.args.get("order", "desc"); score_col, score_label = _sort_key_from_param(sort); sort_ascending = (order == 'asc')
        df_sorted = filtered_df.sort_values(by=[score_col], ascending=sort_ascending, na_position="last")
        
        page = max(1, int(request.args.get("page", 1))); per_page = max(1, min(100, int(request.args.get("per_page", 40))))
        total = len(df_sorted)
        total_pages = max(1, math.ceil(total / per_page))
        page = min(page, total_pages)
        start, end = (page - 1) * per_page, page * per_page
        
        view = df_sorted.iloc[start:end].copy()
        view["rank"] = range(start + 1, start + 1 + len(view))

        cols_to_return = [
            "rank", "title", "addr1", "cat1", "cat3", "firstimage",
            "tour_score", "review_score", "mapx", "mapy"
        ]
        existing_cols = [c for c in cols_to_return if c in view.columns]
        items_list = _df_to_records(view[existing_cols])

        return _json({
            "ok": True, "sort_label": score_label, "sort_col": score_col, 
            "total": total, "page": page, "per_page": per_page, 
            "total_pages": total_pages, "items": items_list,
        })
    except Exception as e: 
        print("âŒ API Error in /api/places:"); traceback.print_exc(); 
        return _json({"ok": False, "error": str(e)}, 500)

@app.get("/api/place-media")
def api_place_media():
    """
    [ì¶”ê°€] íŠ¹ì • ì¥ì†Œì˜ ëª¨ë“  ì´ë¯¸ì§€(CSV, Kakao, ì‚¬ìš©ì ì—…ë¡œë“œ)ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì „ìš© API.
    í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì¹´ë“œê°€ í™”ë©´ì— ë³´ì¼ ë•Œ ì´ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì§€ì—° ë¡œë”©í•©ë‹ˆë‹¤.
    """
    title = _nfc(request.args.get("title", "")); addr1 = _nfc(request.args.get("addr1", ""))
    if not title or not addr1: return _json({"ok": False, "error": "title and addr1 are required."}, 400)
    
    # DataFrameì—ì„œ í•´ë‹¹ ì¥ì†Œë¥¼ ì°¾ì•„ 'firstimage' URLì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    # astype('object')ë¥¼ ì‚¬ìš©í•˜ì—¬ category íƒ€ì… ë¹„êµ ê²½ê³ ë¥¼ í”¼í•©ë‹ˆë‹¤.
    place_mask = (PLACES_DF['title'].astype('object') == title) & (PLACES_DF['addr1'].astype('object') == addr1)
    place_rows = PLACES_DF[place_mask]

    firstimage_url = place_rows.iloc[0]['firstimage'] if not place_rows.empty and 'firstimage' in place_rows.columns else None

    # ëª¨ë“  ì´ë¯¸ì§€ ì†ŒìŠ¤ë¥¼ ê²°í•©í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤. Kakao ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    images = _get_all_images_for_place(title, addr1, firstimage_url, max_n=4, include_user_uploads=True, auto_fetch_if_needed=True)
    coords = _kakao_geocode_coords(title, addr1)
    
    payload: Dict[str, Any] = {"ok": True, "images": images}
    if coords: payload["coords"] = {"y": coords[0], "x": coords[1]}
    return _json(payload)

@app.get("/api/place-details")
def api_place_details():
    _init_session_if_needed()
    title = _nfc(request.args.get("title", ""))
    addr1 = _nfc(request.args.get("addr1", ""))
    mapx = str(request.args.get("mapx", ""))
    mapy = str(request.args.get("mapy", ""))
    if not title or not addr1:
        return _json({"ok": False, "error": "title, addr1ì´ í•„ìš”í•©ë‹ˆë‹¤."}, 400)
    
    kakao_url = _get_kakao_place_url(title, mapx, mapy)
    if kakao_url and kakao_url.startswith("http://"):
        kakao_url = kakao_url.replace("http://", "https://", 1)
        
    key = f"{title}|{addr1}"
    reviews_db = _load_user_reviews()
    place_reviews = reviews_db.get(key, {})
    ratings = place_reviews.get("ratings", {})
    reviews = place_reviews.get("reviews", {})
    
    avg_rating = sum(ratings.values()) / len(ratings) if ratings else 0
    total_ratings = len(ratings)
    
    my_rating = ratings.get(session.get('user_id'))
    my_review_data = next((r for r in reviews.values() if r.get('user_id') == session.get('user_id')), None)
    my_review_text = my_review_data.get('text') if my_review_data else None
    
    return _json({
        "ok": True, "kakao_url": kakao_url, "avg_rating": avg_rating,
        "total_ratings": total_ratings, "my_rating": my_rating, "my_review_text": my_review_text,
    })

@app.get("/api/get-reviews")
def get_reviews():
    title = _nfc(request.args.get("title", "")); addr1 = _nfc(request.args.get("addr1", ""))
    if not title or not addr1: return _json({"ok": False, "error": "í•„ìˆ˜ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."}, 400)
    
    key = f"{title}|{addr1}"
    reviews_db = _load_user_reviews()
    place_reviews_data = reviews_db.get(key, {}).get("reviews", {})
    return _json({"ok": True, "reviews": list(place_reviews_data.values())})

@app.post("/api/submit-review")
def api_submit_review():
    _init_session_if_needed()
    data = request.json
    title = _nfc(data.get("title", "")); addr1 = _nfc(data.get("addr1", ""))
    rating = data.get("rating"); review_text = (data.get("review_text") or "").strip()
    if not title or not addr1: return _json({"ok": False, "error": "í•„ìˆ˜ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."}, 400)

    key = f"{title}|{addr1}"
    user_id = session.get('user_id')
    reviews_db = _load_user_reviews()
    reviews_db.setdefault(key, {"ratings": {}, "reviews": {}})
    
    if rating is not None:
        try:
            rating_val = int(rating)
            if not (0 <= rating_val <= 5): raise ValueError()
            if rating_val == 0 and user_id in reviews_db[key].get("ratings", {}): # ë³„ì  0ì€ ì‚­ì œ
                del reviews_db[key]["ratings"][user_id]
            elif rating_val > 0:
                 reviews_db[key].setdefault("ratings", {})[user_id] = rating_val
        except (ValueError, TypeError):
            return _json({"ok": False, "error": "ë³„ì ì€ 0-5 ì‚¬ì´ì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤."}, 400)

    if review_text:
        review_id = next((rid for rid, r in reviews_db[key].get("reviews", {}).items() if r.get('user_id') == user_id), str(uuid.uuid4()))
        reviews_db[key].setdefault("reviews", {})[review_id] = {
            "user_id": user_id, "text": review_text, "timestamp": datetime.now(timezone.utc).isoformat()
        }

    _save_user_reviews(reviews_db)
    return _json({"ok": True, "message": "í›„ê¸°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."})

@app.get("/img-proxy")
def img_proxy():
    url = request.args.get("u")
    if not url or not url.startswith("http"): return abort(400)
    try:
        _ensure_session()
        r = _SESSION.get(url, stream=True, timeout=10, headers={"Referer": ""})
        r.raise_for_status()
        headers = { "Content-Type": r.headers.get("Content-Type", "image/jpeg"), "Cache-Control": "public, max-age=604800" } # 7ì¼ ìºì‹œ
        return Response(r.iter_content(chunk_size=8192), status=r.status_code, headers=headers)
    except requests.exceptions.RequestException:
        return abort(502)


if __name__ == "__main__":
    start_self_pinging()
    # ë””ë²„ê·¸ ëª¨ë“œëŠ” ë©”ëª¨ë¦¬ë¥¼ ë” ë§ì´ ì‚¬ìš©í•˜ë¯€ë¡œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” Falseë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 5000)), debug=False)